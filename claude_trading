import yfinance as yf
import numpy as np
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from alpaca.trading.client import TradingClient
from alpaca.trading.requests import MarketOrderRequest
from alpaca.trading.enums import OrderSide, TimeInForce, OrderType, OrderClass, OrderStatus
import time
import requests
from bs4 import BeautifulSoup
import logging
from dotenv import load_dotenv
import os
import sys

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Load environment variables
load_dotenv()

# Set up your Alpaca API keys
ALPACA_API_KEY = os.getenv("PK9RIB7H3DVU9FMHROR7")
ALPACA_API_SECRET = os.getenv("dvwSlk4p1ZKBqPsLGJbehu1dAcd82MSwLJ5BgHVh")
ALPACA_BASE_URL = "https://paper-api.alpaca.markets"

# Check if API keys are loaded
if not ALPACA_API_KEY or not ALPACA_API_SECRET:
    logger.error("API keys not found. Please check your .env file.")
    sys.exit(1)

logger.info("Starting the script...")

# Initialize TradingClient with error handling
try:
    trading_client = TradingClient(ALPACA_API_KEY, ALPACA_API_SECRET, paper=True)
    logger.info("TradingClient initialized successfully.")
except ValueError as e:
    logger.error(f"Error initializing TradingClient: {e}")
    logger.error("Please check your API keys and ensure they are correct.")
    sys.exit(1)
except Exception as e:
    logger.error(f"Unexpected error initializing TradingClient: {e}")
    sys.exit(1)

# Verify Alpaca connection
try:
    account = trading_client.get_account()
    logger.info(f"Account status: {account.status}")
    logger.info(f"Account balance: {account.cash}")
except Exception as e:
    logger.error(f"Error connecting to Alpaca API: {e}")

def scrape_news(stock_symbol):
    url = f"https://www.google.com/search?q={stock_symbol}+stock+news"
    headers = {'User-Agent': 'Mozilla/5.0'}
    try:
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        soup = BeautifulSoup(response.content, 'html.parser')
        headlines = [h.get_text() for h in soup.find_all('h3')]
        return headlines
    except requests.RequestException as e:
        logger.error(f"Error scraping news for {stock_symbol}: {e}")
        return []

def analyze_sentiment(headlines):
    analyzer = SentimentIntensityAnalyzer()
    sentiments = [analyzer.polarity_scores(headline)['compound'] for headline in headlines]
    return np.mean(sentiments) if sentiments else 0

def get_stock_volatility_yahoo(symbol):
    try:
        stock_data = yf.download(symbol, period='1mo', interval='1d')
        close_prices = stock_data['Close'].values
        return np.std(close_prices)
    except Exception as e:
        logger.error(f"Error fetching volatility for {symbol}: {e}")
        return None

def get_options_chain(symbol):
    try:
        stock = yf.Ticker(symbol)
        options_dates = stock.options
        latest_date = options_dates[-1]
        return stock.option_chain(latest_date)
    except Exception as e:
        logger.error(f"Error fetching options chain for {symbol}: {e}")
        return None

def place_option_trade(symbol, contract_symbol, qty, option_type='call'):
    try:
        side = OrderSide.BUY if option_type == 'call' else OrderSide.SELL
        market_order_data = MarketOrderRequest(
            symbol=contract_symbol,
            qty=qty,
            side=side,
            type=OrderType.MARKET,
            time_in_force=TimeInForce.GTC,
            order_class=OrderClass.SIMPLE
        )
        order = trading_client.submit_order(order_data=market_order_data)
        logger.info(f"Option order for {contract_symbol} ({side}) is {order.status}.")
    except Exception as e:
        logger.error(f"Error placing options trade for {symbol}: {e}")

def fetch_live_data(symbol):
    try:
        stock = yf.Ticker(symbol)
        data = stock.history(period="1d", interval="1m")
        latest_data = data.iloc[-1]
        logger.info(f"Live data for {symbol} - Close: {latest_data['Close']}, Volume: {latest_data['Volume']}")
        return latest_data
    except Exception as e:
        logger.error(f"Error fetching live data for {symbol}: {e}")
        return None

def automated_trading(stock_symbol, qty=1):
    headlines = scrape_news(stock_symbol)
    sentiment_score = analyze_sentiment(headlines)
    current_volatility = get_stock_volatility_yahoo(stock_symbol)
    live_data = fetch_live_data(stock_symbol)

    if current_volatility is None or live_data is None:
        logger.warning(f"Skipping trade for {stock_symbol} due to missing data")
        return

    options_chain = get_options_chain(stock_symbol)
    if options_chain is None:
        return

    option_contract = options_chain.calls.iloc[0] if sentiment_score > 0.05 else options_chain.puts.iloc[0]
    contract_symbol = option_contract['contractSymbol']

    if sentiment_score > 0.04 and current_volatility > 1:
        place_option_trade(stock_symbol, contract_symbol, qty=qty, option_type='call')
    elif sentiment_score < -0.04 and current_volatility > 1:
        place_option_trade(stock_symbol, contract_symbol, qty=qty, option_type='put')
    else:
        logger.info(f"No significant action for {stock_symbol} - sentiment: {sentiment_score:.2f}, volatility: {current_volatility:.2f}")

def continuous_trading(stock_list, qty=1, interval=300):
    while True:
        for stock_symbol in stock_list:
            try:
                automated_trading(stock_symbol, qty)
            except Exception as e:
                logger.error(f"Error trading {stock_symbol}: {e}")
        
        logger.info(f"Waiting {interval} seconds before next iteration...")
        time.sleep(interval)

if __name__ == "__main__":
    stock_list = ["AAPL", "TSLA", "AMZN", "GOOGL", "MSFT"]
    continuous_trading(stock_list, qty=1, interval=300)